from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from datetime import datetime
import time
import os
import json
from config import FILLER_WORDS, IDEAL_WPM, SLOW_THRESHOLD, FAST_THRESHOLD

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
RESULTS_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'results')
os.makedirs(RESULTS_DIR, exist_ok=True)

# ìš”ì²­ ëª¨ë¸
class TextAnalysisRequest(BaseModel):
    session_id: str = "default"
    text: str

# ë¶„ì„ê¸° í´ë˜ìŠ¤
class SpeechAnalyzer:
    def __init__(self):
        self.start_time = time.time()
        self.word_count = 0
        self.filler_counts = {word: 0 for word in FILLER_WORDS}
        self.all_words = []
        self.full_text = ""

    def add_text(self, text: str) -> None:
        words = text.strip().split()
        self.word_count += len(words)
        self.all_words.extend(words)
        self.full_text += " " + text.strip()
        self._count_fillers(words)

    def _count_fillers(self, words: list) -> None:
        for word in words:
            word_lower = word.lower().strip('.,!?;:')
            if word_lower in self.filler_counts:
                self.filler_counts[word_lower] += 1

    def get_analysis(self) -> dict:
        minutes = (time.time() - self.start_time) / 60
        wpm = self.word_count / minutes if minutes > 0 else 0

        used_fillers = {k: v for k, v in self.filler_counts.items() if v > 0}

        if wpm < SLOW_THRESHOLD:
            wpm_feedback = "ì¡°ê¸ˆ ë” ë¹ ë¥´ê²Œ ë§ì”€í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
        elif wpm > FAST_THRESHOLD:
            wpm_feedback = "ì¡°ê¸ˆ ë” ì²œì²œíˆ, ë˜ë°•ë˜ë°• ë§ì”€í•´ë³´ì„¸ìš”."
        else:
            wpm_feedback = "ì ì ˆí•œ ì†ë„ë¡œ ë§í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."

        return {
            "full_text": self.full_text.strip(),
            "word_count": self.word_count,
            "wpm": round(wpm, 2),
            "wpm_feedback": wpm_feedback,
            "filler_words": used_fillers,
            "total_fillers": sum(used_fillers.values()),
            "speech_duration": round(time.time() - self.start_time, 2),
            "last_updated": datetime.now().isoformat()
        }

# ì¸ë©”ëª¨ë¦¬ ì„¸ì…˜ ì €ì¥ì†Œ
sessions = {}

# ë¶„ì„ ê²°ê³¼ ì €ì¥
def save_result(session_id: str, result: dict) -> None:
    try:
        filename = f"speech_analysis_{session_id}_{int(time.time())}.json"
        filepath = os.path.join(RESULTS_DIR, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# API: í…ìŠ¤íŠ¸ ë¶„ì„
@app.post("/api/analyze")
async def analyze_text(request: TextAnalysisRequest):
    if not request.text:
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸°
    if request.session_id not in sessions:
        sessions[request.session_id] = SpeechAnalyzer()

    analyzer = sessions[request.session_id]
    analyzer.add_text(request.text)
    result = analyzer.get_analysis()

    # íŒŒì¼ ì €ì¥
    save_result(request.session_id, result)

    return {
        "success": True,
        "analysis": result
    }

# API: ì„¸ì…˜ ì´ˆê¸°í™”
@app.post("/api/reset-session")
async def reset_session(session_id: str):
    if session_id in sessions:
        del sessions[session_id]
    return {"success": True}

# API: í•„ëŸ¬ ë‹¨ì–´ ëª©ë¡
@app.get("/api/filler-words")
async def get_filler_words():
    return {
        "success": True,
        "words": FILLER_WORDS
    }

# ğŸ“ ì¶”ê°€: ì„¸ì…˜ë³„ ì „ì²´ ë¶„ì„ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
@app.get("/api/session-history/{session_id}")
async def get_session_history(session_id: str):
    result_files = [f for f in os.listdir(RESULTS_DIR) if f.startswith(f"speech_analysis_{session_id}_")]
    if not result_files:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì„¸ì…˜ì˜ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    history = []
    for fname in sorted(result_files):
        try:
            with open(os.path.join(RESULTS_DIR, fname), 'r', encoding='utf-8') as f:
                history.append(json.load(f))
        except:
            continue

    return {
        "success": True,
        "session_id": session_id,
        "history": history
    }
